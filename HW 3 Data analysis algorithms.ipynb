{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_u5bV-OlT34p"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1*. Измените функцию calc_logloss так, чтобы нули по возможности не попадали в np.log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qMR5pOA38dDw"
   },
   "outputs": [],
   "source": [
    "def calc_logloss(y, y_pred):\n",
    "    not_zero = 10e-8\n",
    "    err = - np.mean(y * np.log(y_pred + not_zero) + (1.0 - y) * np.log(1.0 - y_pred + not_zero))\n",
    "    err = np.sum(err)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R6zfOHMrBvnX",
    "outputId": "46df0625-963f-4401-da30-b5b42bcf1be7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.052680152273363166"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Пример применения\n",
    "y1 = np.array([1, 0, 0, 1])\n",
    "y_pred1 = np.array([0.9, 0.1, 0, 1])\n",
    "calc_logloss(y1, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. Подберите аргументы функции eval_model для логистической регрессии таким образом, чтобы log loss был минимальным.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EEF9rWPNDnss"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    res = 1 / (1 + np.exp(-z))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qtgUN3LW-UIq"
   },
   "outputs": [],
   "source": [
    "def eval_model(X, y, iterations, alpha=1e-4):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    for i in range(1, iterations+1):\n",
    "        z = np.dot(W, X)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        W -= alpha * (1/n * np.dot((y_pred - y), X.T))\n",
    "#         if i % (iterations / 10) == 0:\n",
    "#             print(i, W, err)\n",
    "    return W, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M-aO1NTxOUfo"
   },
   "outputs": [],
   "source": [
    "def calc_std_feat(x):\n",
    "    res = (x - x.mean()) / x.std()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FeKFn2yb1To4"
   },
   "outputs": [],
   "source": [
    "X = np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "              [1, 1, 2, 5, 3, 0, 5, 10, 1, 2],\n",
    "              [500, 700, 750, 600, 1450, 800, 1500, 2000, 450, 1000],\n",
    "              [1, 1, 2, 1, 2,  1, 3, 3, 1, 2]], dtype = np.float64)\n",
    "y = np.array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1], dtype = np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D8EL0iGJOVpe"
   },
   "outputs": [],
   "source": [
    "X_st = X.copy()\n",
    "X_st[2, :] = calc_std_feat(X[2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    },
    "colab_type": "code",
    "id": "gviMxz7EOuI3",
    "outputId": "af9a2576-f4d7-41d7-e216-46e0a068cfad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ],\n",
       "       [ 1.        ,  1.        ,  2.        ,  5.        ,  3.        ,\n",
       "         0.        ,  5.        , 10.        ,  1.        ,  2.        ],\n",
       "       [-0.97958969, -0.56713087, -0.46401617, -0.77336028,  0.97958969,\n",
       "        -0.36090146,  1.08270439,  2.11385144, -1.08270439,  0.05155735],\n",
       "       [ 1.        ,  1.        ,  2.        ,  1.        ,  2.        ,\n",
       "         1.        ,  3.        ,  3.        ,  1.        ,  2.        ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 [ 0.47822106 -0.20918419  0.64605995  1.49531432] 1.0559629735766491\n",
      "1000 [ 0.46074241 -0.27647603  0.64395686  1.46891696] 0.9452143163455625\n",
      "1500 [ 0.44435675 -0.33951515  0.64152026  1.44406912] 0.8478356492175442\n",
      "2000 [ 0.42913461 -0.39751872  0.63899625  1.42106251] 0.7651174792493958\n",
      "2500 [ 0.41513888 -0.44956784  0.63671032  1.40023024] 0.6981290738656131\n",
      "3000 [ 0.40240136 -0.49488241  0.63498247  1.38184975] 0.6468811499046306\n",
      "3500 [ 0.39088925 -0.53321212  0.63401986  1.36601535] 0.6097019385521372\n",
      "4000 [ 0.38049869 -0.56497213  0.63387116  1.35259671] 0.5836772045802464\n",
      "4500 [ 0.37108342 -0.59102182  0.63446603  1.3413119 ] 0.5657145327483051\n",
      "5000 [ 0.36249064 -0.61234585  0.63568321  1.33183158] 0.5532735774580366\n",
      "[ 0.36249064 -0.61234585  0.63568321  1.33183158] 0.5532735774580366\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_lst = [10000, 20000, 30000, 40000]\n",
    "alpha_lst = [1e-2, 5e-2, 0.1, 0.5, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations = 10000, alpha = 0.01:\n",
      " W = [-2.51838389 -0.94526222  0.40028955  3.13247255], logloss = 0.3753577564443368\n",
      "!!!NEW minimum!!!\n",
      "\n",
      "iterations = 10000, alpha = 0.05:\n",
      " W = [-7.45468424 -1.13933276 -1.38016277  6.55241323], logloss = 0.26980751218990945\n",
      "!!!NEW minimum!!!\n",
      "\n",
      "iterations = 10000, alpha = 0.1:\n",
      " W = [-10.744631    -1.38398009  -2.42084781   9.13416686], logloss = 0.2321440525133421\n",
      "!!!NEW minimum!!!\n",
      "\n",
      "iterations = 10000, alpha = 0.5:\n",
      " W = [-24.52791135  -2.59436019  -6.46612462  20.31385673], logloss = 0.1438791521396508\n",
      "!!!NEW minimum!!!\n",
      "\n",
      "iterations = 10000, alpha = 1:\n",
      " W = [-33.60724757  -3.41474448  -9.03744936  27.66630585], logloss = 0.11458801899682125\n",
      "!!!NEW minimum!!!\n",
      "\n",
      "iterations = 20000, alpha = 0.01:\n",
      " W = [-4.27621379 -0.98162746 -0.27399347  4.26180494], logloss = 0.32664857139933945\n",
      "iterations = 20000, alpha = 0.05:\n",
      " W = [-10.744375    -1.38395948  -2.42076898   9.13396218], logloss = 0.2321438248673863\n",
      "iterations = 20000, alpha = 0.1:\n",
      " W = [-15.4271433   -1.7813775   -3.82869298  12.9172959 ], logloss = 0.19343479830682012\n",
      "iterations = 20000, alpha = 0.5:\n",
      " W = [-33.59456965  -3.41360591  -9.03387462  27.65607693], logloss = 0.1146180204023916\n",
      "iterations = 20000, alpha = 1:\n",
      " W = [-44.76666458  -4.39294057 -12.19411645  36.60415234], logloss = 0.09264635910252414\n",
      "!!!NEW minimum!!!\n",
      "\n",
      "iterations = 30000, alpha = 0.01:\n",
      " W = [-5.5601776  -1.03173743 -0.73813215  5.15120103], logloss = 0.29993136081858135\n",
      "iterations = 30000, alpha = 0.05:\n",
      " W = [-13.27245336  -1.59491623  -3.18749601  11.1702598 ], logloss = 0.209738947355593\n",
      "iterations = 30000, alpha = 0.1:\n",
      " W = [-19.03182249  -2.10015312  -4.88452655  15.84696481], logloss = 0.17055122530831646\n",
      "iterations = 30000, alpha = 0.5:\n",
      " W = [-39.81690382  -3.9662702  -10.78961189  32.65807625], logloss = 0.10110129326678378\n",
      "iterations = 30000, alpha = 1:\n",
      " W = [-52.75204658  -5.04414121 -14.49056779  42.88820734], logloss = 0.08169950182197841\n",
      "!!!NEW minimum!!!\n",
      "\n",
      "iterations = 40000, alpha = 0.01:\n",
      " W = [-6.58495724 -1.08568898 -1.0907878   5.89792906], logloss = 0.2825327205501983\n",
      "iterations = 40000, alpha = 0.05:\n",
      " W = [-15.42692617  -1.78135853  -3.82862878  12.91711962], logloss = 0.1934349091449636\n",
      "iterations = 40000, alpha = 0.1:\n",
      " W = [-21.99871339  -2.36615096  -5.74176305  18.25901563], logloss = 0.15508523872267793\n",
      "iterations = 40000, alpha = 0.5:\n",
      " W = [-44.75861236  -4.39225879 -12.19182203  36.59776142], logloss = 0.09265817071124793\n",
      "iterations = 40000, alpha = 1:\n",
      " W = [-59.416728    -5.54424109 -16.44424004  48.04396439], logloss = 0.07417947364171505\n",
      "!!!NEW minimum!!!\n",
      "\n",
      " Best params:\n",
      " iterations = 40000, alpha = 1, logloss = 0.07417947364171505\n",
      "        Weights = [-59.416728    -5.54424109 -16.44424004  48.04396439]\n"
     ]
    }
   ],
   "source": [
    "min_err = np.inf\n",
    "for i in iter_lst:\n",
    "    for a in alpha_lst:\n",
    "        W, err = eval_model(X_st, y, iterations=i, alpha=a)\n",
    "        print (f'iterations = {i}, alpha = {a}:\\n W = {W}, logloss = {err}')\n",
    "        if err < min_err  and err > 0:\n",
    "            min_err = err\n",
    "            alpha_best = a\n",
    "            iter_best = i\n",
    "            W_best = W\n",
    "            print ('!!!NEW minimum!!!\\n')\n",
    "print(f' Best params:\\n iterations = {iter_best}, alpha = {alpha_best}, logloss = {min_err}\\n\\\n",
    "        Weights = {W_best}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод - чем больше alpha и iterations - тем меньше logloss (с риском переобучения)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса 1 (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred_proba).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred_proba(W,X):\n",
    "    return sigmoid(np.dot(W, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31, 0.  , 1.  , 0.  , 0.98, 0.  , 1.  , 0.  , 0.71, 1.  ])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(calc_pred_proba(W, X_st), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 1., 0., 1., 0., 1., 1.])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Создайте функцию calc_pred, возвращающую предсказанный класс (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred(W,X):\n",
    "    return np.round(sigmoid(np.dot(W, X)),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 1., 0., 1., 0., 1., 1.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = calc_pred(W, X_st)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Посчитайте Accuracy, матрицу ошибок, точность и полноту, а также F1 score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$accuracy(a,x) = \\frac{1}{l} \\sum^{l}_{i=1}[a(x_{i})=y_{i}].$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, y_pred):\n",
    "    return np.sum(y == y_pred)/y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = np.array([0., 1., 0., 1., 0., 1., 0., 1., 0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y, y_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_matrix(y, y_pred):\n",
    "    TP, TN, FP, FN = 0,0,0,0\n",
    "    for i in range(y.shape[0]):\n",
    "        if y[i] == y_pred[i]:\n",
    "            if y[i] == 1.0:\n",
    "                TP +=1\n",
    "            else:\n",
    "                TN +=1\n",
    "        else:\n",
    "            if y[i] == 1.0:\n",
    "                FN +=1\n",
    "            else:\n",
    "                FP +=1\n",
    "    print('Conflusion matrix:\\n')\n",
    "    print('      y = | 1 | 0')\n",
    "    print(' '*11 + '_'*7)\n",
    "    print(f'y_pred = 1| {TP} | {FP}')\n",
    "    print(' '*11 + '_'*7)\n",
    "    print(f'y_pred = 0| {FN} | {TN}')\n",
    "    return TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conflusion matrix:\n",
      "\n",
      "      y = | 1 | 0\n",
      "           _______\n",
      "y_pred = 1| 5 | 0\n",
      "           _______\n",
      "y_pred = 0| 0 | 5\n"
     ]
    }
   ],
   "source": [
    "TP, TN, FP, FN = c_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conflusion matrix:\n",
      "\n",
      "      y = | 1 | 0\n",
      "           _______\n",
      "y_pred = 1| 1 | 4\n",
      "           _______\n",
      "y_pred = 0| 4 | 1\n"
     ]
    }
   ],
   "source": [
    "TP2, TN2, FP2, FN2 = c_matrix(y, y_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(TP, FP):\n",
    "    return TP / (TP + FP)\n",
    "\n",
    "def recall(TP, FN):\n",
    "    return TP / (TP + FN)\n",
    "    \n",
    "def f1_score (p, r):\n",
    "    return 2 * p * r / (p + r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 1.0; recall = 1.0; f1 score = 1.0\n"
     ]
    }
   ],
   "source": [
    "p = precision(TP, FP)\n",
    "r = recall(TP,FN)\n",
    "f1 = f1_score(p, r)\n",
    "print (f'Precision = {p}; recall = {r}; f1 score = {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.2; recall = 0.2; f1 score = 0.20000000000000004\n"
     ]
    }
   ],
   "source": [
    "p2 = precision(TP2, FP2)\n",
    "r2 = recall(TP2,FN2)\n",
    "f1_2 = f1_score(p2, r2)\n",
    "print (f'Precision = {p2}; recall = {r2}; f1 score = {f1_2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Могла ли модель переобучиться? Почему?\n",
    "\n",
    "Да, могла, как и любая линейная модель при чрезмерной \"подгонке\" к данным при увеличении количества шагов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7*. Создайте функции eval_model_l1 и eval_model_l2 с применением L1 и L2 регуляризаций соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qtgUN3LW-UIq"
   },
   "outputs": [],
   "source": [
    "def eval_model_l1(X, y, iterations, alpha=1e-4, lambda_ = 1e-4):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    for i in range(1, iterations+1):\n",
    "        z = np.dot(W, X)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        W -= alpha * (1/n * np.dot((y_pred - y), X.T)+ lambda_ * np.sign(W))\n",
    "#         if i % (iterations / 10) == 0:\n",
    "#             print(i, W, err)\n",
    "    return W, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations = 10000, alpha = 0.01:\n",
      " W = [-2.51274502 -0.94368344  0.39955651  3.12663702], logloss = 0.3755487349043972\n",
      "!!!NEW minimum!!!\n",
      "\n",
      "iterations = 10000, alpha = 0.05:\n",
      " W = [-7.41718195 -1.1367363  -1.36753835  6.52352589], logloss = 0.2703273583707399\n",
      "!!!NEW minimum!!!\n",
      "\n",
      "iterations = 10000, alpha = 0.1:\n",
      " W = [-10.66480789  -1.37741394  -2.39588263   9.07005092], logloss = 0.2329250390505042\n",
      "!!!NEW minimum!!!\n",
      "\n",
      "iterations = 10000, alpha = 0.5:\n",
      " W = [-24.13442518  -2.55849245  -6.35326604  19.99384281], logloss = 0.1455176664837899\n",
      "!!!NEW minimum!!!\n",
      "\n",
      "iterations = 10000, alpha = 1:\n",
      " W = [-32.8621246   -3.34708919  -8.82685646  27.06400852], logloss = 0.11649380688157338\n",
      "!!!NEW minimum!!!\n",
      "\n",
      "iterations = 20000, alpha = 0.01:\n",
      " W = [-4.2633311  -0.98069247 -0.2696302   4.25219583], logloss = 0.32695759145278946\n",
      "iterations = 20000, alpha = 0.05:\n",
      " W = [-10.66455222  -1.37739341  -2.39580382   9.06984661], logloss = 0.23292484940026456\n",
      "iterations = 20000, alpha = 0.1:\n",
      " W = [-15.26118334  -1.76673035  -3.77915642  12.78227627], logloss = 0.1946152651870689\n",
      "iterations = 20000, alpha = 0.5:\n",
      " W = [-32.84984687  -3.3459853   -8.82339361  27.05409609], logloss = 0.11652400801196564\n",
      "iterations = 20000, alpha = 1:\n",
      " W = [-43.28245722  -4.26479376 -11.77159817  35.42221686], logloss = 0.09501746878813842\n",
      "!!!NEW minimum!!!\n",
      "\n",
      "iterations = 30000, alpha = 0.01:\n",
      " W = [-5.53874885 -1.03051446 -0.73043191  5.13547474], logloss = 0.3003326311328933\n",
      "iterations = 30000, alpha = 0.05:\n",
      " W = [-13.14903251  -1.58425088  -3.15003194  11.0701412 ], logloss = 0.2107446906114081\n",
      "iterations = 30000, alpha = 0.1:\n",
      " W = [-18.78567021  -2.07801064  -4.81249727  15.64649683], logloss = 0.17196245232739726\n",
      "iterations = 30000, alpha = 0.5:\n",
      " W = [-38.71104395  -3.86798259 -10.47672752  31.77059098], logloss = 0.10323465527828621\n",
      "iterations = 30000, alpha = 1:\n",
      " W = [-50.46464088  -4.85982422 -13.82846845  41.0952575 ], logloss = 0.08457727181165749\n",
      "!!!NEW minimum!!!\n",
      "\n",
      "iterations = 40000, alpha = 0.01:\n",
      " W = [-6.55549846 -1.08381123 -1.08058132  5.87569774], logloss = 0.2829969704327836\n",
      "iterations = 40000, alpha = 0.05:\n",
      " W = [-15.26096758  -1.76671152  -3.77909256  12.78210112], logloss = 0.19461539720977009\n",
      "iterations = 40000, alpha = 0.1:\n",
      " W = [-21.67743725  -2.33699545  -5.64887279  17.99749544], logloss = 0.15663319567859668\n",
      "iterations = 40000, alpha = 0.5:\n",
      " W = [-43.27495141  -4.26415211 -11.76946492  35.41624459], logloss = 0.09502910274483453\n",
      "iterations = 40000, alpha = 1:\n",
      " W = [-56.27563043  -5.30863051 -15.52036427  45.61709721], logloss = 0.07758772854912724\n",
      "!!!NEW minimum!!!\n",
      "\n",
      " Best params:\n",
      " iterations = 40000, alpha = 1, logloss = 0.07758772854912724\n",
      "        Weights = [-56.27563043  -5.30863051 -15.52036427  45.61709721]\n"
     ]
    }
   ],
   "source": [
    "min_err = np.inf\n",
    "for i in iter_lst:\n",
    "    for a in alpha_lst:\n",
    "        W, err = eval_model_l1(X_st, y, iterations=i, alpha=a)\n",
    "        print (f'iterations = {i}, alpha = {a}:\\n W = {W}, logloss = {err}')\n",
    "        if err < min_err  and err > 0:\n",
    "            min_err = err\n",
    "            alpha_best = a\n",
    "            iter_best = i\n",
    "            W_best = W\n",
    "            print ('!!!NEW minimum!!!\\n')\n",
    "print(f' Best params:\\n iterations = {iter_best}, alpha = {alpha_best}, logloss = {min_err}\\n\\\n",
    "        Weights = {W_best}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qtgUN3LW-UIq"
   },
   "outputs": [],
   "source": [
    "def eval_model_l2(X, y, iterations, alpha=1e-4, lambda_=1e-6):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    for i in range(1, iterations+1):\n",
    "        z = np.dot(W, X)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        W -= alpha * (1/n * np.dot((y_pred - y), X.T) + lambda_ * W)\n",
    "#         if i % (iterations / 10) == 0:\n",
    "#             print(i, W, err)\n",
    "    return W, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations = 10000, alpha = 0.01:\n",
      " W = [-2.51825577 -0.94523916  0.40030149  3.13235793], logloss = 0.37536207896918156\n",
      "!!!NEW minimum!!!\n",
      "\n",
      "iterations = 10000, alpha = 0.05:\n",
      " W = [-7.45293763 -1.13920006 -1.37962147  6.55105056], logloss = 0.2698316476191735\n",
      "!!!NEW minimum!!!\n",
      "\n",
      "iterations = 10000, alpha = 0.1:\n",
      " W = [-10.73937479  -1.38353948  -2.41925793   9.12993392], logloss = 0.23219527460339262\n",
      "!!!NEW minimum!!!\n",
      "\n",
      "iterations = 10000, alpha = 0.5:\n",
      " W = [-24.46930143  -2.58904324  -6.44942042  20.2662262 ], logloss = 0.14412069508071992\n",
      "!!!NEW minimum!!!\n",
      "\n",
      "iterations = 10000, alpha = 1:\n",
      " W = [-33.4501508   -3.40059937  -8.993192    27.53948077], logloss = 0.11498364023945437\n",
      "!!!NEW minimum!!!\n",
      "\n",
      "iterations = 20000, alpha = 0.01:\n",
      " W = [-4.27580423 -0.98159227 -0.27388078  4.26149241], logloss = 0.32665831155283265\n",
      "iterations = 20000, alpha = 0.05:\n",
      " W = [-10.73911897  -1.38351889  -2.41917914   9.12972938], logloss = 0.23219504923406364\n",
      "iterations = 20000, alpha = 0.1:\n",
      " W = [-15.41171687  -1.78001385  -3.82415647  12.90474404], logloss = 0.1935439355026784\n",
      "iterations = 20000, alpha = 0.5:\n",
      " W = [-33.43766113  -3.39947728  -8.98967017  27.52940221], logloss = 0.11501343115505272\n",
      "iterations = 20000, alpha = 1:\n",
      " W = [-44.33903374  -4.35655969 -12.07242951  36.26439314], logloss = 0.093316035987166\n",
      "!!!NEW minimum!!!\n",
      "\n",
      "iterations = 30000, alpha = 0.01:\n",
      " W = [-5.55939684 -1.03167941 -0.7378948   5.15060771], logloss = 0.29994595185156014\n",
      "iterations = 30000, alpha = 0.05:\n",
      " W = [-13.26251936  -1.59405252  -3.18454169  11.16219524], logloss = 0.20981952908090068\n",
      "iterations = 30000, alpha = 0.1:\n",
      " W = [-19.00368264  -2.09762693  -4.87637379  15.82405636], logloss = 0.17071140254094175\n",
      "iterations = 30000, alpha = 0.5:\n",
      " W = [-39.53587234  -3.94157704 -10.71022738  32.4329352 ], logloss = 0.10163358999618292\n",
      "iterations = 30000, alpha = 1:\n",
      " W = [-51.97302142  -4.98271444 -14.26475933  42.27962178], logloss = 0.08265912658209659\n",
      "!!!NEW minimum!!!\n",
      "\n",
      "iterations = 40000, alpha = 0.01:\n",
      " W = [-6.58372911 -1.08559798 -1.09040745  5.89698327], logloss = 0.2825520249896685\n",
      "iterations = 40000, alpha = 0.05:\n",
      " W = [-15.41150008  -1.7799949   -3.82409236  12.90456804], logloss = 0.1935440481798334\n",
      "iterations = 40000, alpha = 0.1:\n",
      " W = [-21.95608461  -2.36229671  -5.72953218  18.22433661], logloss = 0.15528882346618986\n",
      "iterations = 40000, alpha = 0.5:\n",
      " W = [-44.33125097  -4.35589858 -12.0702136   36.25821121], logloss = 0.09332762874584238\n",
      "iterations = 40000, alpha = 1:\n",
      " W = [-58.21813887  -5.45675081 -16.09086127  47.1216264 ], logloss = 0.07545282340545188\n",
      "!!!NEW minimum!!!\n",
      "\n",
      " Best params:\n",
      " iterations = 40000, alpha = 1, logloss = 0.07545282340545188\n",
      "        Weights = [-58.21813887  -5.45675081 -16.09086127  47.1216264 ]\n"
     ]
    }
   ],
   "source": [
    "min_err = np.inf\n",
    "for i in iter_lst:\n",
    "    for a in alpha_lst:\n",
    "        W, err = eval_model_l2(X_st, y, iterations=i, alpha=a)\n",
    "        print (f'iterations = {i}, alpha = {a}:\\n W = {W}, logloss = {err}')\n",
    "        if err < min_err  and err > 0:\n",
    "            min_err = err\n",
    "            alpha_best = a\n",
    "            iter_best = i\n",
    "            W_best = W\n",
    "            print ('!!!NEW minimum!!!\\n')\n",
    "print(f' Best params:\\n iterations = {iter_best}, alpha = {alpha_best}, logloss = {min_err}\\n\\\n",
    "        Weights = {W_best}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
